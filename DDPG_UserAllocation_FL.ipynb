{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DDPG UserAllocation-FL",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPt4XyRnaT+EaN0j+MKTxiJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skydvn/Compression-aided-FL-Optimization/blob/main/DDPG_UserAllocation_FL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ul_KghhUdDHL"
      },
      "source": [
        "# Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDkrrZRDURFQ"
      },
      "source": [
        "import numpy as np\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zXKviudaLfu"
      },
      "source": [
        "dtype = np.float32\n",
        "\n",
        "class SumRate():\n",
        "    def __init__(self, MAX_EP_STEPS, gArray, r_req, weight, pel):\n",
        "        self.H = gArray\n",
        "        self.I = self.H.shape[0]\n",
        "        self.r_req = r_req\n",
        "        self.weight = weight        \n",
        "        self.n0 = 0.1*1e-6\n",
        "        self.stopEps = 1e-6\n",
        "        self.pMax = 1e-3*np.array([0.7, 0.8, 0.9, 1.0])\n",
        "        self.pMin = np.zeros([1,self.I])\n",
        "        self.MAX_EP_STEPS = MAX_EP_STEPS\n",
        "        self.pel = pel     \n",
        "        self.state_walk = 0;\n",
        "                \n",
        "        self.action_low = self.pMin\n",
        "        self.action_high = self.pMax        \n",
        "        H_space = np.reshape(self.H, (1, self.I*self.I))\n",
        "        d_rate = -np.ones((1,self.I)) * 1\n",
        "        self.observation_space = np.concatenate((H_space,d_rate),axis=1)\n",
        "        \n",
        "\n",
        "    def step(self, action, state):\n",
        "      state_rs = np.reshape(state,(self.I+1,self.I))\n",
        "      H = state_rs[0:self.I,0:self.I]\n",
        "      d_rate = state_rs[self.I, 0:self.I]\n",
        "      diagH = np.diag(H)\n",
        "      print(\"Action is: {}\".format(action))\n",
        "      rate = np.log(self.n0 + np.matmul(action,H.transpose())) \\\n",
        "          - np.log(self.n0 + action*diagH)        \n",
        "      print(\"rate is: {}\".format(rate))\n",
        "      sumrate = np.sum(weight * rate) * math.log2(math.exp(1))\n",
        "      reward = sumrate \\\n",
        "          - np.sum(pel * (sum(d_rate < 0) * d_rate**2));\n",
        "      \n",
        "      # define the next state\n",
        "      d_rate = rate - self.r_req\n",
        "      d_rate = d_rate.reshape((1,4))\n",
        "      print(np.shape(d_rate))\n",
        "      state_next = np.concatenate((H, d_rate), axis=0)\n",
        "      state_next = np.reshape(state_next,(1,self.I*self.I+self.I))\n",
        "  \n",
        "      # return the done flag\n",
        "      self.state_walk += 1\n",
        "      if self.state_walk > MAX_EP_STEPS:\n",
        "          done = True\n",
        "      else: done = False\n",
        "      return state_next, reward, done\n",
        "\n",
        "    def reset(self):\n",
        "        d_rate = -np.ones((1,self.I)) * 1\n",
        "        hnx1 = np.random.randn(self.I, self.I)\n",
        "        hnx2 = np.random.randn(self.I, self.I)\n",
        "        fading_n = hnx1 ** 2 + hnx2 ** 2        \n",
        "        print(np.shape(d_rate))\n",
        "        state_next = np.concatenate((self.H * fading_n, d_rate), axis=0)\n",
        "        state = np.reshape(state_next,(1,self.I*self.I+self.I))\n",
        "        \n",
        "        return state"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAsbNtN_ab9n"
      },
      "source": [
        "DDPG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSRkRFKGaMP9",
        "outputId": "1cbc3dc5-90c3-4e9e-99ef-5b48beae35d9"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Lambda, concatenate\n",
        "# from env_SumRate import SumRate\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# import gym\n",
        "import argparse\n",
        "import numpy as np\n",
        "import random\n",
        "from collections import deque\n",
        "\n",
        "tf.keras.backend.set_floatx('float64')\n",
        "\n",
        "# parser = argparse.ArgumentParser()\n",
        "# parser.add_argument('--gamma', type=float, default=0.99)\n",
        "# parser.add_argument('--actor_lr', type=float, default=0.0005)\n",
        "# parser.add_argument('--critic_lr', type=float, default=0.001)\n",
        "# parser.add_argument('--batch_size', type=int, default=64)\n",
        "# parser.add_argument('--tau', type=float, default=0.05)\n",
        "# parser.add_argument('--train_start', type=int, default=2000)\n",
        "\n",
        "# args = parser.parse_args()\n",
        "class Configuration: \n",
        "  def __init__(self):\n",
        "    self.gamma = 0.99\n",
        "    self.actor_lr = 0.0005\n",
        "    self.critic_lr = 0.001\n",
        "    self.batch_size = 64\n",
        "    self.tau = 0.05\n",
        "    self.train_start = 2000\n",
        "\n",
        "args = Configuration()\n",
        "print(args.batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FopEl1nJiiXt"
      },
      "source": [
        "# Actor Critic Definition\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwZ6y0Neig7t"
      },
      "source": [
        "class ReplayBuffer:\n",
        "    def __init__(self, capacity=20000):\n",
        "        self.buffer = deque(maxlen=capacity)\n",
        "    \n",
        "    def put(self, state, action, reward, next_state, done):\n",
        "        self.buffer.append([state, action, reward, next_state, done])\n",
        "    \n",
        "    def sample(self):\n",
        "        sample = random.sample(self.buffer, args.batch_size)\n",
        "        states, actions, rewards, next_states, done = map(np.asarray, zip(*sample))\n",
        "        states = np.array(states).reshape(args.batch_size, -1)\n",
        "        next_states = np.array(next_states).reshape(args.batch_size, -1)\n",
        "        return states, actions, rewards, next_states, done\n",
        "    \n",
        "    def size(self):\n",
        "        return len(self.buffer)\n",
        "\n",
        "class Critic:\n",
        "    def __init__(self, state_dim, action_dim):\n",
        "        self.state_dim = state_dim\n",
        "        self.action_dim = action_dim\n",
        "        self.model = self.create_model()\n",
        "        self.opt = tf.keras.optimizers.Adam(args.critic_lr)\n",
        "\n",
        "    def create_model(self):\n",
        "        state_input = Input((self.state_dim,))\n",
        "        s1 = Dense(64, activation='relu')(state_input)\n",
        "        s2 = Dense(32, activation='relu')(s1)\n",
        "        action_input = Input((self.action_dim,))\n",
        "        a1 = Dense(32, activation='relu')(action_input)\n",
        "        c1 = concatenate([s2, a1], axis=-1)\n",
        "        c2 = Dense(16, activation='relu')(c1)\n",
        "        output = Dense(1, activation='linear')(c2)\n",
        "        return tf.keras.Model([state_input, action_input], output)\n",
        "    \n",
        "    def predict(self, inputs):\n",
        "        return self.model.predict(inputs)\n",
        "    \n",
        "    def q_grads(self, states, actions):\n",
        "        actions = tf.convert_to_tensor(actions)\n",
        "        with tf.GradientTape() as tape:\n",
        "            tape.watch(actions)\n",
        "            q_values = self.model([states, actions])\n",
        "            q_values = tf.squeeze(q_values)\n",
        "        return tape.gradient(q_values, actions)\n",
        "\n",
        "    def compute_loss(self, v_pred, td_targets):\n",
        "        mse = tf.keras.losses.MeanSquaredError()\n",
        "        return mse(td_targets, v_pred)\n",
        "\n",
        "    def train(self, states, actions, td_targets):\n",
        "        with tf.GradientTape() as tape:\n",
        "            v_pred = self.model([states, actions], training=True)\n",
        "            assert v_pred.shape == td_targets.shape\n",
        "            loss = self.compute_loss(v_pred, tf.stop_gradient(td_targets))\n",
        "        grads = tape.gradient(loss, self.model.trainable_variables)\n",
        "        self.opt.apply_gradients(zip(grads, self.model.trainable_variables))\n",
        "        return loss\n",
        "\n",
        "class Actor:\n",
        "    def __init__(self, state_dim, action_dim, action_bound):\n",
        "        self.state_dim = state_dim\n",
        "        self.action_dim = action_dim\n",
        "        self.action_bound = action_bound\n",
        "        self.model = self.create_model()\n",
        "        self.opt = tf.keras.optimizers.Adam(args.actor_lr)\n",
        "\n",
        "    def create_model(self):\n",
        "        return tf.keras.Sequential([\n",
        "            Input((self.state_dim,)),\n",
        "            Dense(32, activation='relu'),\n",
        "            Dense(32, activation='relu'),\n",
        "            Dense(self.action_dim, activation='sigmoid'),\n",
        "            Lambda(lambda x: x * self.action_bound)\n",
        "        ])\n",
        "\n",
        "    def train(self, states, q_grads):\n",
        "        with tf.GradientTape() as tape:\n",
        "            grads = tape.gradient(self.model(states), self.model.trainable_variables, -q_grads)\n",
        "        self.opt.apply_gradients(zip(grads, self.model.trainable_variables))\n",
        "    \n",
        "    def predict(self, state):\n",
        "        return self.model.predict(state)\n",
        "\n",
        "    def get_action(self, state):\n",
        "        state = np.reshape(state, [1, self.state_dim])\n",
        "        return self.model.predict(state)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWGF0knXau_o"
      },
      "source": [
        "class Agent:\n",
        "    def __init__(self, env):\n",
        "        self.env = env\n",
        "        self.state_dim = self.env.observation_space.shape[1]\n",
        "        self.action_dim = self.env.action_low.shape[1]\n",
        "        self.action_bound = self.env.action_high\n",
        "\n",
        "        self.buffer = ReplayBuffer()\n",
        "\n",
        "        self.actor = Actor(self.state_dim, self.action_dim, self.action_bound)\n",
        "        self.critic = Critic(self.state_dim, self.action_dim)\n",
        "        \n",
        "        self.target_actor = Actor(self.state_dim, self.action_dim, self.action_bound)\n",
        "        self.target_critic = Critic(self.state_dim, self.action_dim)\n",
        "\n",
        "        actor_weights = self.actor.model.get_weights()\n",
        "        critic_weights = self.critic.model.get_weights()\n",
        "        self.target_actor.model.set_weights(actor_weights)\n",
        "        self.target_critic.model.set_weights(critic_weights)\n",
        "        \n",
        "    \n",
        "    def target_update(self):\n",
        "        actor_weights = self.actor.model.get_weights()\n",
        "        t_actor_weights = self.target_actor.model.get_weights()\n",
        "        critic_weights = self.critic.model.get_weights()\n",
        "        t_critic_weights = self.target_critic.model.get_weights()\n",
        "\n",
        "        for i in range(len(actor_weights)):\n",
        "            t_actor_weights[i] = args.tau * actor_weights[i] + (1 - args.tau) * t_actor_weights[i]\n",
        "\n",
        "        for i in range(len(critic_weights)):\n",
        "            t_critic_weights[i] = args.tau * critic_weights[i] + (1 - args.tau) * t_critic_weights[i]\n",
        "        \n",
        "        self.target_actor.model.set_weights(t_actor_weights)\n",
        "        self.target_critic.model.set_weights(t_critic_weights)\n",
        "\n",
        "\n",
        "    def td_target(self, rewards, q_values, dones):\n",
        "        targets = np.asarray(q_values)\n",
        "        for i in range(q_values.shape[0]):\n",
        "            if dones[i]:\n",
        "                targets[i] = rewards[i]\n",
        "            else:\n",
        "                targets[i] = args.gamma * q_values[i]\n",
        "        return targets\n",
        "\n",
        "    def list_to_batch(self, list):\n",
        "        batch = list[0]\n",
        "        for elem in list[1:]:\n",
        "            batch = np.append(batch, elem, axis=0)\n",
        "        return batch\n",
        "    \n",
        "    def ou_noise(self, x, rho=0.15, mu=0, dt=1e-1, sigma=0.2, dim=1):\n",
        "        return x + rho * (mu-x) * dt + sigma * np.sqrt(dt) * np.random.normal(size=dim)\n",
        "    \n",
        "    # Training phase of an Agent\n",
        "    def replay(self):\n",
        "        for _ in range(10):\n",
        "            states, actions, rewards, next_states, dones = self.buffer.sample()\n",
        "            target_q_values = self.target_critic.predict([next_states, self.target_actor.predict(next_states)])\n",
        "            td_targets = self.td_target(rewards, target_q_values, dones)\n",
        "            \n",
        "            #### Primary Network ####\n",
        "            # Critic Update\n",
        "            self.critic.train(states, actions, td_targets)\n",
        "            \n",
        "            s_actions = self.actor.predict(states)\n",
        "            s_grads = self.critic.q_grads(states, s_actions)\n",
        "            grads = np.array(s_grads).reshape((-1, self.action_dim))\n",
        "\n",
        "            # Actor Update\n",
        "            self.actor.train(states, grads)\n",
        "\n",
        "            #### Target Network  ####\n",
        "            self.target_update()\n",
        "\n",
        "    def train(self, max_episodes=100):\n",
        "        ep_rewardall = []\n",
        "        for ep in range(max_episodes):\n",
        "            episode_reward, done = 0, False\n",
        "\n",
        "            state = self.env.reset()\n",
        "            bg_noise = np.zeros(self.action_dim)\n",
        "            while not done:\n",
        "                # self.env.render()\n",
        "                action = self.actor.get_action(state)\n",
        "                noise = self.ou_noise(bg_noise, dim=self.action_dim)\n",
        "                action = np.clip(action + noise, 0, self.action_bound)  # noise is created here and make action less than zero\n",
        "\n",
        "                next_state, reward, done = self.env.step(action, state)\n",
        "                ##########################################\n",
        "                H = [[0.4310, 0.0002, 0.0129, 0.0011],\n",
        "                      [0.0002, 0.3018, 0.0005, 0.0031], \n",
        "                      [0.2605, 0.0008, 0.4266, 0.0099],\n",
        "                      [0.0039, 0.0054, 0.1007, 0.0634]]\n",
        "                gArray = np.array(H)\n",
        "                print(np.shape(gArray))\n",
        "                H = gArray\n",
        "                I = H.shape[0]\n",
        "                r_req = 1e-3*np.array([0.7, 0.8, 0.9, 1.0])\n",
        "                weight = np.array([1,1,1,1])        \n",
        "                n0 = 0.1*1e-6\n",
        "                stopEps = 1e-6\n",
        "                pMax = 1e-3*np.array([0.7, 0.8, 0.9, 1.0])\n",
        "                pMin = 1e-8*np.ones([1,I])\n",
        "                MAX_EP_STEPS = 100\n",
        "                pel = 1e1     \n",
        "                step = 0;\n",
        "                state = np.reshape(state,(I+1,I))\n",
        "                H = state[0:I,0:I]\n",
        "                d_rate = state[I, 0:I]\n",
        "                diagH = np.diag(H)\n",
        "                print(\"Action is: {}\".format(action))\n",
        "                rate = np.log(n0 + np.matmul(action,H.transpose())) \\\n",
        "                    - np.log(n0 + action*diagH)        \n",
        "                print(\"rate is: {}\".format(rate))\n",
        "                sumrate = np.sum(weight * rate) * math.log2(math.exp(1))\n",
        "                reward = sumrate \\\n",
        "                    - np.sum(pel * (sum(d_rate < 0) * d_rate**2));\n",
        "                \n",
        "                # define the next state\n",
        "                d_rate = rate - r_req\n",
        "                d_rate = d_rate.reshape((1,4))\n",
        "                print(np.shape(d_rate))\n",
        "                state_next = np.concatenate((H, d_rate), axis=0)\n",
        "                state_next = np.reshape(state_next,(1,I*I+I))\n",
        "            \n",
        "                # return the done flag\n",
        "                step += 1\n",
        "                if step > MAX_EP_STEPS:\n",
        "                    done = True\n",
        "                next_state = state_next\n",
        "\n",
        "                self.buffer.put(state, action, (reward+8)/8, next_state, done)\n",
        "                bg_noise = noise\n",
        "                episode_reward += reward\n",
        "                state = next_state\n",
        "            if self.buffer.size() >= args.batch_size and self.buffer.size() >= args.train_start:\n",
        "                self.replay()   \n",
        "            ep_rewardall.append(episode_reward)\n",
        "            print('EP{} EpisodeReward={}'.format(ep, episode_reward))\n",
        "            # wandb.log({'Reward': episode_reward})\n",
        "            \n",
        "        return ep_rewardall\n",
        "\n",
        "\n",
        "def main():    \n",
        "    ################## training\n",
        "    H = [[0.4310, 0.0002, 0.0129, 0.0011],\n",
        "     [0.0002, 0.3018, 0.0005, 0.0031],\n",
        "     [0.2605, 0.0008, 0.4266, 0.0099],\n",
        "     [0.0039, 0.0054, 0.1007, 0.0634]]\n",
        "    gArray = np.array(H)\n",
        "    MAX_EP_STEPS = 100\n",
        "    r_req = 1e-3*np.array([0.7, 0.8, 0.9, 1.0])\n",
        "    weight = np.array([1,1,1,1])\n",
        "    pel = 1e1\n",
        "    \n",
        "    env_sr = SumRate(MAX_EP_STEPS, gArray, r_req, weight, pel)\n",
        "    agent = Agent(env_sr)\n",
        "    ep_rewardall = agent.train(max_episodes=50)\n",
        "    \n",
        "    ### plot\n",
        "    plt.plot(ep_rewardall, \"^-\")\n",
        "    plt.xlabel(\"Episode\")\n",
        "    plt.ylabel(\" Epsiodic Reward\")\n",
        "    plt.show()\n",
        "    \n",
        "    #env_name = 'Pendulum-v0'\n",
        "    # env = gym.make(env_name)\n",
        "    # agent = Agent(env)\n",
        "    # agent.train(max_episodes=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6ACCymfXayTK",
        "outputId": "f77a1a6b-7e8b-47ac-c02d-ff35d662efe0"
      },
      "source": [
        "################## training\n",
        "H = np.array([[0.4310, 0.0002, 0.0129, 0.0011],\n",
        "              [0.0002, 0.3018, 0.0005, 0.0031],\n",
        "              [0.2605, 0.0008, 0.4266, 0.0099],\n",
        "              [0.0039, 0.0054, 0.1007, 0.0634]]) \n",
        "gArray = np.array(H)\n",
        "MAX_EP_STEPS = 100\n",
        "r_req = 1e-3*np.array([0.7, 0.8, 0.9, 1.0])\n",
        "weight = np.array([1,1,1,1])\n",
        "pel = 1e1\n",
        "\n",
        "env_sr = SumRate(MAX_EP_STEPS, gArray, r_req, weight, pel)\n",
        "agent = Agent(env_sr)\n",
        "ep_rewardall = agent.train(max_episodes=50)\n",
        "\n",
        "### plot\n",
        "plt.plot(ep_rewardall, \"^-\")\n",
        "plt.xlabel(\"Episode\")\n",
        "plt.ylabel(\" Epsiodic Reward\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
            "(1, 4)\n",
            "Action is: [0.     0.     0.0009 0.001 ]\n",
            "rate is: [4.82478647 4.12472796 0.10589777 0.54769612]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.     0.0009 0.001 ]\n",
            "rate is: [4.82478647 4.12472796 0.10589777 0.54769612]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.    ]\n",
            "rate is: [4.81712807e+00 1.01418940e-01 1.57306884e-03 6.46263696e+00]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.    ]\n",
            "rate is: [4.81712807e+00 1.01418940e-01 1.57306884e-03 6.46263696e+00]\n",
            "(1, 4)\n",
            "Action is: [0.0007 0.     0.0009 0.    ]\n",
            "rate is: [0.46902078 3.18911261 0.85621294 6.52377023]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.0007 0.     0.0009 0.    ]\n",
            "rate is: [0.46902078 3.18911261 0.85621294 6.52377023]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.    ]\n",
            "rate is: [4.81712807e+00 1.01418940e-01 1.57306884e-03 6.46263696e+00]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.    ]\n",
            "rate is: [4.81712807e+00 1.01418940e-01 1.57306884e-03 6.46263696e+00]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [4.83996983 0.27113894 0.10731288 0.59790495]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [4.83996983 0.27113894 0.10731288 0.59790495]\n",
            "(1, 4)\n",
            "Action is: [0.0007 0.0008 0.0009 0.001 ]\n",
            "rate is: [0.48368182 0.28051045 0.90320983 0.67244099]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.0007 0.0008 0.0009 0.001 ]\n",
            "rate is: [0.48368182 0.28051045 0.90320983 0.67244099]\n",
            "(1, 4)\n",
            "Action is: [0.0007 0.0008 0.0009 0.001 ]\n",
            "rate is: [0.48368182 0.28051045 0.90320983 0.67244099]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.0007 0.0008 0.0009 0.001 ]\n",
            "rate is: [0.48368182 0.28051045 0.90320983 0.67244099]\n",
            "(1, 4)\n",
            "Action is: [0.0007 0.0008 0.0009 0.001 ]\n",
            "rate is: [0.48368182 0.28051045 0.90320983 0.67244099]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.0007 0.0008 0.0009 0.001 ]\n",
            "rate is: [0.48368182 0.28051045 0.90320983 0.67244099]\n",
            "(1, 4)\n",
            "Action is: [0.0007 0.0008 0.0009 0.001 ]\n",
            "rate is: [0.48368182 0.28051045 0.90320983 0.67244099]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.0007 0.0008 0.0009 0.001 ]\n",
            "rate is: [0.48368182 0.28051045 0.90320983 0.67244099]\n",
            "(1, 4)\n",
            "Action is: [0.0007 0.0008 0.0009 0.001 ]\n",
            "rate is: [0.48368182 0.28051045 0.90320983 0.67244099]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.0007 0.0008 0.0009 0.001 ]\n",
            "rate is: [0.48368182 0.28051045 0.90320983 0.67244099]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [4.83996983 0.27113894 0.10731288 0.59790495]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [4.83996983 0.27113894 0.10731288 0.59790495]\n",
            "(1, 4)\n",
            "Action is: [0.0007 0.0008 0.0009 0.001 ]\n",
            "rate is: [0.48368182 0.28051045 0.90320983 0.67244099]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.0007 0.0008 0.0009 0.001 ]\n",
            "rate is: [0.48368182 0.28051045 0.90320983 0.67244099]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [4.83996983 0.27113894 0.10731288 0.59790495]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [4.83996983 0.27113894 0.10731288 0.59790495]\n",
            "(1, 4)\n",
            "Action is: [0.0007 0.0008 0.0009 0.001 ]\n",
            "rate is: [0.48368182 0.28051045 0.90320983 0.67244099]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.0007 0.0008 0.0009 0.001 ]\n",
            "rate is: [0.48368182 0.28051045 0.90320983 0.67244099]\n",
            "(1, 4)\n",
            "Action is: [0.     0.     0.0009 0.001 ]\n",
            "rate is: [4.82478647 4.12472796 0.10589777 0.54769612]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.     0.0009 0.001 ]\n",
            "rate is: [4.82478647 4.12472796 0.10589777 0.54769612]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [4.83996983 0.27113894 0.10731288 0.59790495]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [4.83996983 0.27113894 0.10731288 0.59790495]\n",
            "(1, 4)\n",
            "Action is: [0.0007 0.0008 0.0009 0.001 ]\n",
            "rate is: [0.48368182 0.28051045 0.90320983 0.67244099]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.0007 0.0008 0.0009 0.001 ]\n",
            "rate is: [0.48368182 0.28051045 0.90320983 0.67244099]\n",
            "(1, 4)\n",
            "Action is: [0.0007 0.0008 0.0009 0.001 ]\n",
            "rate is: [0.48368182 0.28051045 0.90320983 0.67244099]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.0007 0.0008 0.0009 0.001 ]\n",
            "rate is: [0.48368182 0.28051045 0.90320983 0.67244099]\n",
            "(1, 4)\n",
            "Action is: [0.0007 0.0008 0.0009 0.001 ]\n",
            "rate is: [0.48368182 0.28051045 0.90320983 0.67244099]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.0007 0.0008 0.0009 0.001 ]\n",
            "rate is: [0.48368182 0.28051045 0.90320983 0.67244099]\n",
            "(1, 4)\n",
            "Action is: [0.0007 0.0008 0.0009 0.001 ]\n",
            "rate is: [0.48368182 0.28051045 0.90320983 0.67244099]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.0007 0.0008 0.0009 0.001 ]\n",
            "rate is: [0.48368182 0.28051045 0.90320983 0.67244099]\n",
            "(1, 4)\n",
            "Action is: [0.0007 0.0008 0.0009 0.001 ]\n",
            "rate is: [0.48368182 0.28051045 0.90320983 0.67244099]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.0007 0.0008 0.0009 0.001 ]\n",
            "rate is: [0.48368182 0.28051045 0.90320983 0.67244099]\n",
            "(1, 4)\n",
            "Action is: [0.0007 0.0008 0.0009 0.001 ]\n",
            "rate is: [0.48368182 0.28051045 0.90320983 0.67244099]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.0007 0.0008 0.0009 0.001 ]\n",
            "rate is: [0.48368182 0.28051045 0.90320983 0.67244099]\n",
            "(1, 4)\n",
            "Action is: [0.0007 0.0008 0.0009 0.001 ]\n",
            "rate is: [0.48368182 0.28051045 0.90320983 0.67244099]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.0007 0.0008 0.0009 0.001 ]\n",
            "rate is: [0.48368182 0.28051045 0.90320983 0.67244099]\n",
            "(1, 4)\n",
            "Action is: [0.0007 0.0008 0.0009 0.001 ]\n",
            "rate is: [0.48368182 0.28051045 0.90320983 0.67244099]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.0007 0.0008 0.0009 0.001 ]\n",
            "rate is: [0.48368182 0.28051045 0.90320983 0.67244099]\n",
            "(1, 4)\n",
            "Action is: [0.0007 0.0008 0.0009 0.001 ]\n",
            "rate is: [0.48368182 0.28051045 0.90320983 0.67244099]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.0007 0.0008 0.0009 0.001 ]\n",
            "rate is: [0.48368182 0.28051045 0.90320983 0.67244099]\n",
            "(1, 4)\n",
            "Action is: [0.0007 0.     0.0009 0.001 ]\n",
            "rate is: [0.47784004 4.16299169 0.90257162 0.6259237 ]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.0007 0.     0.0009 0.001 ]\n",
            "rate is: [0.47784004 4.16299169 0.90257162 0.6259237 ]\n",
            "(1, 4)\n",
            "Action is: [0.0007 0.0008 0.0009 0.001 ]\n",
            "rate is: [0.48368182 0.28051045 0.90320983 0.67244099]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.0007 0.0008 0.0009 0.001 ]\n",
            "rate is: [0.48368182 0.28051045 0.90320983 0.67244099]\n",
            "(1, 4)\n",
            "Action is: [0.0007 0.0008 0.0009 0.001 ]\n",
            "rate is: [0.48368182 0.28051045 0.90320983 0.67244099]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.0007 0.0008 0.0009 0.001 ]\n",
            "rate is: [0.48368182 0.28051045 0.90320983 0.67244099]\n",
            "(1, 4)\n",
            "Action is: [0.0007 0.0008 0.0009 0.001 ]\n",
            "rate is: [0.48368182 0.28051045 0.90320983 0.67244099]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.0007 0.0008 0.0009 0.001 ]\n",
            "rate is: [0.48368182 0.28051045 0.90320983 0.67244099]\n",
            "(1, 4)\n",
            "Action is: [0.0007 0.0008 0.0009 0.001 ]\n",
            "rate is: [0.48368182 0.28051045 0.90320983 0.67244099]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.0007 0.0008 0.0009 0.001 ]\n",
            "rate is: [0.48368182 0.28051045 0.90320983 0.67244099]\n",
            "(1, 4)\n",
            "Action is: [0.0007 0.0008 0.0009 0.001 ]\n",
            "rate is: [0.48368182 0.28051045 0.90320983 0.67244099]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.0007 0.0008 0.0009 0.001 ]\n",
            "rate is: [0.48368182 0.28051045 0.90320983 0.67244099]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [4.83996983 0.27113894 0.10731288 0.59790495]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [4.83996983 0.27113894 0.10731288 0.59790495]\n",
            "(1, 4)\n",
            "Action is: [0.0007 0.0008 0.0009 0.001 ]\n",
            "rate is: [0.48368182 0.28051045 0.90320983 0.67244099]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.0007 0.0008 0.0009 0.001 ]\n",
            "rate is: [0.48368182 0.28051045 0.90320983 0.67244099]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [4.83996983 0.27113894 0.10731288 0.59790495]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [4.83996983 0.27113894 0.10731288 0.59790495]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [4.83996983 0.27113894 0.10731288 0.59790495]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [4.83996983 0.27113894 0.10731288 0.59790495]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.    ]\n",
            "rate is: [4.81712807e+00 1.01418940e-01 1.57306884e-03 6.46263696e+00]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.    ]\n",
            "rate is: [4.81712807e+00 1.01418940e-01 1.57306884e-03 6.46263696e+00]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.    ]\n",
            "rate is: [4.81712807e+00 1.01418940e-01 1.57306884e-03 6.46263696e+00]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.    ]\n",
            "rate is: [4.81712807e+00 1.01418940e-01 1.57306884e-03 6.46263696e+00]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.    ]\n",
            "rate is: [4.81712807e+00 1.01418940e-01 1.57306884e-03 6.46263696e+00]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.    ]\n",
            "rate is: [4.81712807e+00 1.01418940e-01 1.57306884e-03 6.46263696e+00]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.    ]\n",
            "rate is: [4.81712807e+00 1.01418940e-01 1.57306884e-03 6.46263696e+00]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.    ]\n",
            "rate is: [4.81712807e+00 1.01418940e-01 1.57306884e-03 6.46263696e+00]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.    ]\n",
            "rate is: [4.81712807e+00 1.01418940e-01 1.57306884e-03 6.46263696e+00]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.    ]\n",
            "rate is: [4.81712807e+00 1.01418940e-01 1.57306884e-03 6.46263696e+00]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.    ]\n",
            "rate is: [4.81712807e+00 1.01418940e-01 1.57306884e-03 6.46263696e+00]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.    ]\n",
            "rate is: [4.81712807e+00 1.01418940e-01 1.57306884e-03 6.46263696e+00]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.    ]\n",
            "rate is: [4.81712807e+00 1.01418940e-01 1.57306884e-03 6.46263696e+00]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.    ]\n",
            "rate is: [4.81712807e+00 1.01418940e-01 1.57306884e-03 6.46263696e+00]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.    ]\n",
            "rate is: [4.81712807e+00 1.01418940e-01 1.57306884e-03 6.46263696e+00]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.    ]\n",
            "rate is: [4.81712807e+00 1.01418940e-01 1.57306884e-03 6.46263696e+00]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.    ]\n",
            "rate is: [4.81712807e+00 1.01418940e-01 1.57306884e-03 6.46263696e+00]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.    ]\n",
            "rate is: [4.81712807e+00 1.01418940e-01 1.57306884e-03 6.46263696e+00]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.    ]\n",
            "rate is: [4.81712807e+00 1.01418940e-01 1.57306884e-03 6.46263696e+00]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.    ]\n",
            "rate is: [4.81712807e+00 1.01418940e-01 1.57306884e-03 6.46263696e+00]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.    ]\n",
            "rate is: [4.81712807e+00 1.01418940e-01 1.57306884e-03 6.46263696e+00]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.    ]\n",
            "rate is: [4.81712807e+00 1.01418940e-01 1.57306884e-03 6.46263696e+00]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.    ]\n",
            "rate is: [4.81712807e+00 1.01418940e-01 1.57306884e-03 6.46263696e+00]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.    ]\n",
            "rate is: [4.81712807e+00 1.01418940e-01 1.57306884e-03 6.46263696e+00]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.    ]\n",
            "rate is: [4.81712807e+00 1.01418940e-01 1.57306884e-03 6.46263696e+00]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.    ]\n",
            "rate is: [4.81712807e+00 1.01418940e-01 1.57306884e-03 6.46263696e+00]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.    ]\n",
            "rate is: [4.81712807e+00 1.01418940e-01 1.57306884e-03 6.46263696e+00]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.    ]\n",
            "rate is: [4.81712807e+00 1.01418940e-01 1.57306884e-03 6.46263696e+00]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [4.83996983 0.27113894 0.10731288 0.59790495]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [4.83996983 0.27113894 0.10731288 0.59790495]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [4.83996983 0.27113894 0.10731288 0.59790495]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [4.83996983 0.27113894 0.10731288 0.59790495]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [4.83996983 0.27113894 0.10731288 0.59790495]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [4.83996983 0.27113894 0.10731288 0.59790495]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [4.83996983 0.27113894 0.10731288 0.59790495]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [4.83996983 0.27113894 0.10731288 0.59790495]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [4.83996983 0.27113894 0.10731288 0.59790495]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [4.83996983 0.27113894 0.10731288 0.59790495]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.    ]\n",
            "rate is: [4.81712807e+00 1.01418940e-01 1.57306884e-03 6.46263696e+00]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.    ]\n",
            "rate is: [4.81712807e+00 1.01418940e-01 1.57306884e-03 6.46263696e+00]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.    ]\n",
            "rate is: [4.81712807e+00 1.01418940e-01 1.57306884e-03 6.46263696e+00]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.    ]\n",
            "rate is: [4.81712807e+00 1.01418940e-01 1.57306884e-03 6.46263696e+00]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.    ]\n",
            "rate is: [4.81712807e+00 1.01418940e-01 1.57306884e-03 6.46263696e+00]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.    ]\n",
            "rate is: [4.81712807e+00 1.01418940e-01 1.57306884e-03 6.46263696e+00]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.    ]\n",
            "rate is: [4.81712807e+00 1.01418940e-01 1.57306884e-03 6.46263696e+00]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.    ]\n",
            "rate is: [4.81712807e+00 1.01418940e-01 1.57306884e-03 6.46263696e+00]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.    ]\n",
            "rate is: [4.81712807e+00 1.01418940e-01 1.57306884e-03 6.46263696e+00]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.    ]\n",
            "rate is: [4.81712807e+00 1.01418940e-01 1.57306884e-03 6.46263696e+00]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.    ]\n",
            "rate is: [4.81712807e+00 1.01418940e-01 1.57306884e-03 6.46263696e+00]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.    ]\n",
            "rate is: [4.81712807e+00 1.01418940e-01 1.57306884e-03 6.46263696e+00]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [4.83996983 0.27113894 0.10731288 0.59790495]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [4.83996983 0.27113894 0.10731288 0.59790495]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [4.83996983 0.27113894 0.10731288 0.59790495]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [4.83996983 0.27113894 0.10731288 0.59790495]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [4.83996983 0.27113894 0.10731288 0.59790495]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [4.83996983 0.27113894 0.10731288 0.59790495]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [4.83996983 0.27113894 0.10731288 0.59790495]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [4.83996983 0.27113894 0.10731288 0.59790495]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [4.83996983 0.27113894 0.10731288 0.59790495]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [4.83996983 0.27113894 0.10731288 0.59790495]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [4.83996983 0.27113894 0.10731288 0.59790495]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [4.83996983 0.27113894 0.10731288 0.59790495]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [4.83996983 0.27113894 0.10731288 0.59790495]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [4.83996983 0.27113894 0.10731288 0.59790495]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [4.83996983 0.27113894 0.10731288 0.59790495]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [4.83996983 0.27113894 0.10731288 0.59790495]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [4.83996983 0.27113894 0.10731288 0.59790495]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [4.83996983 0.27113894 0.10731288 0.59790495]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [4.83996983 0.27113894 0.10731288 0.59790495]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [4.83996983 0.27113894 0.10731288 0.59790495]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.    ]\n",
            "rate is: [4.81712807e+00 1.01418940e-01 1.57306884e-03 6.46263696e+00]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.    ]\n",
            "rate is: [4.81712807e+00 1.01418940e-01 1.57306884e-03 6.46263696e+00]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [4.83996983 0.27113894 0.10731288 0.59790495]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [4.83996983 0.27113894 0.10731288 0.59790495]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [4.83996983 0.27113894 0.10731288 0.59790495]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [4.83996983 0.27113894 0.10731288 0.59790495]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [4.83996983 0.27113894 0.10731288 0.59790495]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [4.83996983 0.27113894 0.10731288 0.59790495]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [4.83996983 0.27113894 0.10731288 0.59790495]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [4.83996983 0.27113894 0.10731288 0.59790495]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [4.83996983 0.27113894 0.10731288 0.59790495]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [4.83996983 0.27113894 0.10731288 0.59790495]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [4.83996983 0.27113894 0.10731288 0.59790495]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [4.83996983 0.27113894 0.10731288 0.59790495]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.    ]\n",
            "rate is: [4.81712807e+00 1.01418940e-01 1.57306884e-03 6.46263696e+00]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.    ]\n",
            "rate is: [4.81712807e+00 1.01418940e-01 1.57306884e-03 6.46263696e+00]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.    ]\n",
            "rate is: [4.81712807e+00 1.01418940e-01 1.57306884e-03 6.46263696e+00]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.    ]\n",
            "rate is: [4.81712807e+00 1.01418940e-01 1.57306884e-03 6.46263696e+00]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.    ]\n",
            "rate is: [4.81712807e+00 1.01418940e-01 1.57306884e-03 6.46263696e+00]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.    ]\n",
            "rate is: [4.81712807e+00 1.01418940e-01 1.57306884e-03 6.46263696e+00]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.    ]\n",
            "rate is: [4.81712807e+00 1.01418940e-01 1.57306884e-03 6.46263696e+00]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.    ]\n",
            "rate is: [4.81712807e+00 1.01418940e-01 1.57306884e-03 6.46263696e+00]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.     0.    ]\n",
            "rate is: [1.06666317 0.         2.59264106 4.2571992 ]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.     0.    ]\n",
            "rate is: [1.06666317 0.         2.59264106 4.2571992 ]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.     0.    ]\n",
            "rate is: [1.06666317 0.         2.59264106 4.2571992 ]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.     0.    ]\n",
            "rate is: [1.06666317 0.         2.59264106 4.2571992 ]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.     0.    ]\n",
            "rate is: [1.06666317 0.         2.59264106 4.2571992 ]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.     0.    ]\n",
            "rate is: [1.06666317 0.         2.59264106 4.2571992 ]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.     0.    ]\n",
            "rate is: [1.06666317 0.         2.59264106 4.2571992 ]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.     0.    ]\n",
            "rate is: [1.06666317 0.         2.59264106 4.2571992 ]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.     0.    ]\n",
            "rate is: [1.06666317 0.         2.59264106 4.2571992 ]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.     0.    ]\n",
            "rate is: [1.06666317 0.         2.59264106 4.2571992 ]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.     0.    ]\n",
            "rate is: [1.06666317 0.         2.59264106 4.2571992 ]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.     0.    ]\n",
            "rate is: [1.06666317 0.         2.59264106 4.2571992 ]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.     0.    ]\n",
            "rate is: [1.06666317 0.         2.59264106 4.2571992 ]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.     0.    ]\n",
            "rate is: [1.06666317 0.         2.59264106 4.2571992 ]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.     0.    ]\n",
            "rate is: [1.06666317 0.         2.59264106 4.2571992 ]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.     0.    ]\n",
            "rate is: [1.06666317 0.         2.59264106 4.2571992 ]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.     0.    ]\n",
            "rate is: [1.06666317 0.         2.59264106 4.2571992 ]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.     0.    ]\n",
            "rate is: [1.06666317 0.         2.59264106 4.2571992 ]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.     0.    ]\n",
            "rate is: [1.06666317 0.         2.59264106 4.2571992 ]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.     0.    ]\n",
            "rate is: [1.06666317 0.         2.59264106 4.2571992 ]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.     0.    ]\n",
            "rate is: [1.06666317 0.         2.59264106 4.2571992 ]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.     0.    ]\n",
            "rate is: [1.06666317 0.         2.59264106 4.2571992 ]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.    ]\n",
            "rate is: [4.81712807e+00 1.01418940e-01 1.57306884e-03 6.46263696e+00]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.    ]\n",
            "rate is: [4.81712807e+00 1.01418940e-01 1.57306884e-03 6.46263696e+00]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.     0.    ]\n",
            "rate is: [1.06666317 0.         2.59264106 4.2571992 ]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.     0.    ]\n",
            "rate is: [1.06666317 0.         2.59264106 4.2571992 ]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.     0.    ]\n",
            "rate is: [1.06666317 0.         2.59264106 4.2571992 ]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.     0.    ]\n",
            "rate is: [1.06666317 0.         2.59264106 4.2571992 ]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.     0.    ]\n",
            "rate is: [1.06666317 0.         2.59264106 4.2571992 ]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.     0.    ]\n",
            "rate is: [1.06666317 0.         2.59264106 4.2571992 ]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.     0.    ]\n",
            "rate is: [1.06666317 0.         2.59264106 4.2571992 ]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.     0.    ]\n",
            "rate is: [1.06666317 0.         2.59264106 4.2571992 ]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.     0.    ]\n",
            "rate is: [1.06666317 0.         2.59264106 4.2571992 ]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.     0.    ]\n",
            "rate is: [1.06666317 0.         2.59264106 4.2571992 ]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.     0.    ]\n",
            "rate is: [1.06666317 0.         2.59264106 4.2571992 ]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.     0.    ]\n",
            "rate is: [1.06666317 0.         2.59264106 4.2571992 ]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.     0.    ]\n",
            "rate is: [1.06666317 0.         2.59264106 4.2571992 ]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.     0.    ]\n",
            "rate is: [1.06666317 0.         2.59264106 4.2571992 ]\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.     0.    ]\n",
            "rate is: [1.06666317 0.         2.59264106 4.2571992 ]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.     0.    ]\n",
            "rate is: [1.06666317 0.         2.59264106 4.2571992 ]\n",
            "(1, 4)\n",
            "EP0 EpisodeReward=-3795.7890768705956\n",
            "(1, 4)\n",
            "Action is: [0.    0.    0.    0.001]\n",
            "rate is: [3.79782216 4.12897638 5.86674021 0.        ]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.    0.    0.    0.001]\n",
            "rate is: [3.79782216 4.12897638 5.86674021 0.        ]\n",
            "(1, 4)\n",
            "EP1 EpisodeReward=-140.10013004330884\n",
            "(1, 4)\n",
            "Action is: [0. 0. 0. 0.]\n",
            "rate is: [0. 0. 0. 0.]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0. 0. 0. 0.]\n",
            "rate is: [0. 0. 0. 0.]\n",
            "(1, 4)\n",
            "EP2 EpisodeReward=-160.0\n",
            "(1, 4)\n",
            "Action is: [0.0007 0.0008 0.     0.    ]\n",
            "rate is: [4.00073418e-03 5.66730176e-04 6.98129131e+00 5.05434696e+00]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.0007 0.0008 0.     0.    ]\n",
            "rate is: [4.00073418e-03 5.66730176e-04 6.98129131e+00 5.05434696e+00]\n",
            "(1, 4)\n",
            "EP3 EpisodeReward=-142.62965490319178\n",
            "(1, 4)\n",
            "Action is: [0.     0.     0.0009 0.001 ]\n",
            "rate is: [5.28193744 3.07928395 0.02826076 1.2598095 ]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.     0.0009 0.001 ]\n",
            "rate is: [5.28193744 3.07928395 0.02826076 1.2598095 ]\n",
            "(1, 4)\n",
            "EP4 EpisodeReward=-146.07901478851647\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.    ]\n",
            "rate is: [4.57369932e+00 7.82841581e-04 6.27105012e-03 7.79341871e+00]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.    ]\n",
            "rate is: [4.57369932e+00 7.82841581e-04 6.27105012e-03 7.79341871e+00]\n",
            "(1, 4)\n",
            "EP5 EpisodeReward=-142.1478435322254\n",
            "(1, 4)\n",
            "Action is: [0.0007 0.0008 0.0009 0.001 ]\n",
            "rate is: [0.04779594 0.00668865 0.90989252 1.59945099]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.0007 0.0008 0.0009 0.001 ]\n",
            "rate is: [0.04779594 0.00668865 0.90989252 1.59945099]\n",
            "(1, 4)\n",
            "EP6 EpisodeReward=-156.30117791590496\n",
            "(1, 4)\n",
            "Action is: [0.0007 0.0008 0.0009 0.    ]\n",
            "rate is: [8.70436783e-01 1.85670581e-03 4.78004766e+00 5.96497516e+00]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.0007 0.0008 0.0009 0.    ]\n",
            "rate is: [8.70436783e-01 1.85670581e-03 4.78004766e+00 5.96497516e+00]\n",
            "(1, 4)\n",
            "EP7 EpisodeReward=-143.23975537905886\n",
            "(1, 4)\n",
            "Action is: [0.     0.     0.0009 0.    ]\n",
            "rate is: [6.74439483 2.06813062 0.         7.84372039]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.     0.0009 0.    ]\n",
            "rate is: [6.74439483 2.06813062 0.         7.84372039]\n",
            "(1, 4)\n",
            "EP8 EpisodeReward=-135.97011671114942\n",
            "(1, 4)\n",
            "Action is: [0.     0.     0.0009 0.    ]\n",
            "rate is: [6.50266666 3.05299805 0.         8.55778358]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.     0.0009 0.    ]\n",
            "rate is: [6.50266666 3.05299805 0.         8.55778358]\n",
            "(1, 4)\n",
            "EP9 EpisodeReward=-133.86781798025743\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.     0.001 ]\n",
            "rate is: [2.26865347e+00 9.22333251e-04 3.49723954e+00 2.04174791e-02]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.     0.001 ]\n",
            "rate is: [2.26865347e+00 9.22333251e-04 3.49723954e+00 2.04174791e-02]\n",
            "(1, 4)\n",
            "EP10 EpisodeReward=-151.65078790768735\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [5.76573163 0.07086398 0.03783248 0.47602214]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [5.76573163 0.07086398 0.03783248 0.47602214]\n",
            "(1, 4)\n",
            "EP11 EpisodeReward=-150.83823694273815\n",
            "(1, 4)\n",
            "Action is: [0.0007 0.0008 0.     0.001 ]\n",
            "rate is: [1.86594950e-02 3.48929273e-03 7.56309347e+00 4.21743117e-01]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.0007 0.0008 0.     0.001 ]\n",
            "rate is: [1.86594950e-02 3.48929273e-03 7.56309347e+00 4.21743117e-01]\n",
            "(1, 4)\n",
            "EP12 EpisodeReward=-148.44836190681397\n",
            "(1, 4)\n",
            "Action is: [0.0007 0.     0.     0.    ]\n",
            "rate is: [0.         2.42021702 7.61107803 3.25933535]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.0007 0.     0.     0.    ]\n",
            "rate is: [0.         2.42021702 7.61107803 3.25933535]\n",
            "(1, 4)\n",
            "EP13 EpisodeReward=-140.82567342993514\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.     0.    ]\n",
            "rate is: [1.77413979 0.         3.39464674 3.54994791]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.     0.    ]\n",
            "rate is: [1.77413979 0.         3.39464674 3.54994791]\n",
            "(1, 4)\n",
            "EP14 EpisodeReward=-147.4215250678165\n",
            "(1, 4)\n",
            "Action is: [0.0007 0.     0.     0.    ]\n",
            "rate is: [0.         0.45406833 8.64125271 2.76782758]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.0007 0.     0.     0.    ]\n",
            "rate is: [0.         0.45406833 8.64125271 2.76782758]\n",
            "(1, 4)\n",
            "EP15 EpisodeReward=-142.8850943211254\n",
            "(1, 4)\n",
            "Action is: [0.0007 0.0008 0.0009 0.001 ]\n",
            "rate is: [0.11287901 0.24785494 0.51067003 0.39639457]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.0007 0.0008 0.0009 0.001 ]\n",
            "rate is: [0.11287901 0.24785494 0.51067003 0.39639457]\n",
            "(1, 4)\n",
            "EP16 EpisodeReward=-158.17095330160845\n",
            "(1, 4)\n",
            "Action is: [0.0007 0.0008 0.0009 0.001 ]\n",
            "rate is: [1.25895271e-02 2.77745876e-03 5.98807268e-02 2.89178841e+00]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.0007 0.0008 0.0009 0.001 ]\n",
            "rate is: [1.25895271e-02 2.77745876e-03 5.98807268e-02 2.89178841e+00]\n",
            "(1, 4)\n",
            "EP17 EpisodeReward=-155.71947169546004\n",
            "(1, 4)\n",
            "Action is: [0.0007     0.0008     0.00042312 0.001     ]\n",
            "rate is: [0.10288448 0.01051589 0.48485118 2.22816897]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.0007     0.0008     0.00042312 0.001     ]\n",
            "rate is: [0.10288448 0.01051589 0.48485118 2.22816897]\n",
            "(1, 4)\n",
            "EP18 EpisodeReward=-155.9223371182399\n",
            "(1, 4)\n",
            "Action is: [0.0007 0.0008 0.0009 0.    ]\n",
            "rate is: [0.34851653 0.0088472  0.0306367  6.04129426]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.0007 0.0008 0.0009 0.    ]\n",
            "rate is: [0.34851653 0.0088472  0.0306367  6.04129426]\n",
            "(1, 4)\n",
            "EP19 EpisodeReward=-150.72448844157185\n",
            "(1, 4)\n",
            "Action is: [0.     0.     0.0009 0.    ]\n",
            "rate is: [4.20270293 2.84914705 0.         7.3147422 ]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.     0.0009 0.    ]\n",
            "rate is: [4.20270293 2.84914705 0.         7.3147422 ]\n",
            "(1, 4)\n",
            "EP20 EpisodeReward=-139.27338870390858\n",
            "(1, 4)\n",
            "Action is: [0.0007 0.     0.0009 0.    ]\n",
            "rate is: [0.01152786 2.4984772  1.75866858 6.39957311]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.0007 0.     0.0009 0.    ]\n",
            "rate is: [0.01152786 2.4984772  1.75866858 6.39957311]\n",
            "(1, 4)\n",
            "EP21 EpisodeReward=-144.60897332940868\n",
            "(1, 4)\n",
            "Action is: [0.0007 0.     0.     0.    ]\n",
            "rate is: [0.         0.14521706 8.88513083 5.16186671]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.0007 0.     0.     0.    ]\n",
            "rate is: [0.         0.14521706 8.88513083 5.16186671]\n",
            "(1, 4)\n",
            "EP22 EpisodeReward=-139.52496237718435\n",
            "(1, 4)\n",
            "Action is: [0.0007 0.     0.     0.    ]\n",
            "rate is: [0.         0.1742092  6.18659969 3.30111125]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.0007 0.     0.     0.    ]\n",
            "rate is: [0.         0.1742092  6.18659969 3.30111125]\n",
            "(1, 4)\n",
            "EP23 EpisodeReward=-146.06079572196907\n",
            "(1, 4)\n",
            "Action is: [0.0007 0.     0.     0.001 ]\n",
            "rate is: [6.38160495e-04 3.44195441e+00 8.64254014e+00 1.42858754e-03]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.0007 0.     0.     0.001 ]\n",
            "rate is: [6.38160495e-04 3.44195441e+00 8.64254014e+00 1.42858754e-03]\n",
            "(1, 4)\n",
            "EP24 EpisodeReward=-142.5627779551922\n",
            "(1, 4)\n",
            "Action is: [0.    0.    0.    0.001]\n",
            "rate is: [4.16294946 1.30841747 5.13151416 0.        ]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.    0.    0.    0.001]\n",
            "rate is: [4.16294946 1.30841747 5.13151416 0.        ]\n",
            "(1, 4)\n",
            "EP25 EpisodeReward=-144.7032760275372\n",
            "(1, 4)\n",
            "Action is: [0.0007 0.     0.     0.001 ]\n",
            "rate is: [3.03248812e-03 3.73192927e+00 3.19606083e+00 6.30100171e-03]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.0007 0.     0.     0.001 ]\n",
            "rate is: [3.03248812e-03 3.73192927e+00 3.19606083e+00 6.30100171e-03]\n",
            "(1, 4)\n",
            "EP26 EpisodeReward=-149.99155765269373\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [6.4224312  0.24134897 0.03380141 0.25260963]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [6.4224312  0.24134897 0.03380141 0.25260963]\n",
            "(1, 4)\n",
            "EP27 EpisodeReward=-149.97299360980148\n",
            "(1, 4)\n",
            "Action is: [0.     0.     0.0009 0.001 ]\n",
            "rate is: [6.12586017 3.74954612 0.06806719 0.91054223]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.     0.0009 0.001 ]\n",
            "rate is: [6.12586017 3.74954612 0.06806719 0.91054223]\n",
            "(1, 4)\n",
            "EP28 EpisodeReward=-144.34096536496256\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.     0.    ]\n",
            "rate is: [0.79969532 0.         2.15613882 5.44680229]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.     0.    ]\n",
            "rate is: [0.79969532 0.         2.15613882 5.44680229]\n",
            "(1, 4)\n",
            "EP29 EpisodeReward=-147.87755809788882\n",
            "(1, 4)\n",
            "Action is: [0.0007 0.     0.     0.001 ]\n",
            "rate is: [9.38755565e-04 2.51805736e+00 7.07204323e+00 3.37641492e-03]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.0007 0.     0.     0.001 ]\n",
            "rate is: [9.38755565e-04 2.51805736e+00 7.07204323e+00 3.37641492e-03]\n",
            "(1, 4)\n",
            "EP30 EpisodeReward=-146.15818395782176\n",
            "(1, 4)\n",
            "Action is: [0.     0.     0.0009 0.001 ]\n",
            "rate is: [5.56221336 4.37863966 0.00883535 0.0276843 ]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.     0.0009 0.001 ]\n",
            "rate is: [5.56221336 4.37863966 0.00883535 0.0276843 ]\n",
            "(1, 4)\n",
            "EP31 EpisodeReward=-145.6056939383857\n",
            "(1, 4)\n",
            "Action is: [0.         0.         0.         0.00081482]\n",
            "rate is: [4.62963268 3.24139625 6.02467906 0.        ]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.         0.         0.         0.00081482]\n",
            "rate is: [4.62963268 3.24139625 6.02467906 0.        ]\n",
            "(1, 4)\n",
            "EP32 EpisodeReward=-139.9527309904428\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [3.06673162 0.04116563 0.09918227 0.15174189]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.001 ]\n",
            "rate is: [3.06673162 0.04116563 0.09918227 0.15174189]\n",
            "(1, 4)\n",
            "EP33 EpisodeReward=-155.15424499495674\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.    ]\n",
            "rate is: [4.00236812e+00 1.13251372e-02 8.58368463e-04 8.19177753e+00]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.0009 0.    ]\n",
            "rate is: [4.00236812e+00 1.13251372e-02 8.58368463e-04 8.19177753e+00]\n",
            "(1, 4)\n",
            "EP34 EpisodeReward=-142.38998944906663\n",
            "(1, 4)\n",
            "Action is: [0.0007 0.     0.     0.    ]\n",
            "rate is: [0.         0.88812785 8.11376926 3.87106421]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.0007 0.     0.     0.    ]\n",
            "rate is: [0.         0.88812785 8.11376926 3.87106421]\n",
            "(1, 4)\n",
            "EP35 EpisodeReward=-141.4282425420446\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.     0.001 ]\n",
            "rate is: [3.02057545 0.0066727  4.24471333 0.03343202]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.     0.001 ]\n",
            "rate is: [3.02057545 0.0066727  4.24471333 0.03343202]\n",
            "(1, 4)\n",
            "EP36 EpisodeReward=-149.46054503513955\n",
            "(1, 4)\n",
            "Action is: [0.0007 0.0008 0.     0.001 ]\n",
            "rate is: [2.99002067e-03 2.18886153e-02 8.74494559e+00 2.27538915e+00]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.0007 0.0008 0.     0.001 ]\n",
            "rate is: [2.99002067e-03 2.18886153e-02 8.74494559e+00 2.27538915e+00]\n",
            "(1, 4)\n",
            "EP37 EpisodeReward=-144.0651254419822\n",
            "(1, 4)\n",
            "Action is: [0. 0. 0. 0.]\n",
            "rate is: [0. 0. 0. 0.]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0. 0. 0. 0.]\n",
            "rate is: [0. 0. 0. 0.]\n",
            "(1, 4)\n",
            "EP38 EpisodeReward=-160.0\n",
            "(1, 4)\n",
            "Action is: [0.0007 0.     0.0009 0.001 ]\n",
            "rate is: [0.04172214 4.02393399 0.53516519 0.04655456]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.0007 0.     0.0009 0.001 ]\n",
            "rate is: [0.04172214 4.02393399 0.53516519 0.04655456]\n",
            "(1, 4)\n",
            "EP39 EpisodeReward=-153.2952538457296\n",
            "(1, 4)\n",
            "Action is: [0.         0.0008     0.         0.00039732]\n",
            "rate is: [2.76908573 0.00470299 3.79931124 0.45096436]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.         0.0008     0.         0.00039732]\n",
            "rate is: [2.76908573 0.00470299 3.79931124 0.45096436]\n",
            "(1, 4)\n",
            "EP40 EpisodeReward=-149.8664172354217\n",
            "(1, 4)\n",
            "Action is: [0.     0.     0.0009 0.001 ]\n",
            "rate is: [3.28224493 3.21342265 0.005596   1.00647077]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.     0.0009 0.001 ]\n",
            "rate is: [3.28224493 3.21342265 0.005596   1.00647077]\n",
            "(1, 4)\n",
            "EP41 EpisodeReward=-149.1686288877166\n",
            "(1, 4)\n",
            "Action is: [0.     0.     0.0009 0.    ]\n",
            "rate is: [4.07640235 1.76452132 0.         5.64423949]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.     0.0009 0.    ]\n",
            "rate is: [4.07640235 1.76452132 0.         5.64423949]\n",
            "(1, 4)\n",
            "EP42 EpisodeReward=-143.4304120525217\n",
            "(1, 4)\n",
            "Action is: [0.    0.    0.    0.001]\n",
            "rate is: [2.76222491 4.17142512 3.99864769 0.        ]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.    0.    0.    0.001]\n",
            "rate is: [2.76222491 4.17142512 3.99864769 0.        ]\n",
            "(1, 4)\n",
            "EP43 EpisodeReward=-144.22802829574346\n",
            "(1, 4)\n",
            "Action is: [0.0007 0.     0.0009 0.001 ]\n",
            "rate is: [0.05365742 5.80718759 0.02957226 1.35057472]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.0007 0.     0.0009 0.001 ]\n",
            "rate is: [0.05365742 5.80718759 0.02957226 1.35057472]\n",
            "(1, 4)\n",
            "EP44 EpisodeReward=-149.55345675224393\n",
            "(1, 4)\n",
            "Action is: [0.     0.0008 0.     0.001 ]\n",
            "rate is: [2.41864737e+00 7.63158004e-04 5.96688323e+00 3.41703317e-01]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.0008 0.     0.001 ]\n",
            "rate is: [2.41864737e+00 7.63158004e-04 5.96688323e+00 3.41703317e-01]\n",
            "(1, 4)\n",
            "EP45 EpisodeReward=-147.40816189767133\n",
            "(1, 4)\n",
            "Action is: [0.     0.     0.0009 0.    ]\n",
            "rate is: [5.00486269 1.01765573 0.         8.16259851]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.     0.0009 0.    ]\n",
            "rate is: [5.00486269 1.01765573 0.         8.16259851]\n",
            "(1, 4)\n",
            "EP46 EpisodeReward=-139.5352021514595\n",
            "(1, 4)\n",
            "Action is: [0. 0. 0. 0.]\n",
            "rate is: [0. 0. 0. 0.]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0. 0. 0. 0.]\n",
            "rate is: [0. 0. 0. 0.]\n",
            "(1, 4)\n",
            "EP47 EpisodeReward=-160.0\n",
            "(1, 4)\n",
            "Action is: [0.     0.     0.0009 0.001 ]\n",
            "rate is: [6.15696486 4.70870813 0.07120384 0.05175535]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.     0.0009 0.001 ]\n",
            "rate is: [6.15696486 4.70870813 0.07120384 0.05175535]\n",
            "(1, 4)\n",
            "EP48 EpisodeReward=-144.14675486053835\n",
            "(1, 4)\n",
            "Action is: [0.     0.     0.0009 0.001 ]\n",
            "rate is: [4.71107534 3.01637621 2.03154314 0.75273213]\n",
            "(1, 4)\n",
            "(4, 4)\n",
            "Action is: [0.     0.     0.0009 0.001 ]\n",
            "rate is: [4.71107534 3.01637621 2.03154314 0.75273213]\n",
            "(1, 4)\n",
            "EP49 EpisodeReward=-144.83478384385177\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaLZAlMEay3k"
      },
      "source": [
        "###########################################\n",
        "H = [[0.4310, 0.0002, 0.0129, 0.0011],\n",
        "      [0.0002, 0.3018, 0.0005, 0.0031], \n",
        "      [0.2605, 0.0008, 0.4266, 0.0099],\n",
        "      [0.0039, 0.0054, 0.1007, 0.0634]]\n",
        "gArray = np.array(H)\n",
        "print(np.shape(gArray))\n",
        "H = gArray\n",
        "I = H.shape[0]\n",
        "r_req = 1e-3*np.array([0.7, 0.8, 0.9, 1.0])\n",
        "weight = np.array([1,1,1,1])        \n",
        "n0 = 0.1*1e-6\n",
        "stopEps = 1e-6\n",
        "pMax = 1e-3*np.array([0.7, 0.8, 0.9, 1.0])\n",
        "pMin = 1e-8*np.ones([1,I])\n",
        "MAX_EP_STEPS = 100\n",
        "pel = 1e1     \n",
        "step = 0;\n",
        "##########################################\n",
        "state = np.reshape(state,(I+1,I))\n",
        "H = state[0:I,0:I]\n",
        "d_rate = state[I][0:I]\n",
        "diagH = np.diag(H)\n",
        "\n",
        "print(\"Action is: {}\".format(action))\n",
        "rate = np.log(n0 + np.matmul(action,H.transpose())) \\\n",
        "    - np.log(n0 + action*diagH)        \n",
        "print(\"rate is: {}\".format(rate))\n",
        "# print(\"diagH is: {}\".format(diagH))\n",
        "# print(\"n0 is: {}\".format(n0))\n",
        "# print(\"Log1 is: {}\".format(n0 + np.matmul(action,H.transpose())))\n",
        "# print(\"Log2 is: {}\".format(n0 + action*diagH))\n",
        "sumrate = np.sum(weight * rate) * math.log2(math.exp(1))\n",
        "reward = sumrate \\\n",
        "    - np.sum(pel * (sum(d_rate < 0) * d_rate**2));\n",
        "\n",
        "# define the next state\n",
        "d_rate = rate - r_req\n",
        "d_rate = d_rate.reshape((1,4))\n",
        "print(\"d_rate is: {}\".format(d_rate))\n",
        "print(np.shape(d_rate))\n",
        "\n",
        "state_next = np.concatenate((H, d_rate), axis=0)\n",
        "print(\"state_next is: {}\".format(state_next))\n",
        "state_next = np.reshape(state_next,(1,I*I+I))\n",
        "# return the done flag\n",
        "step += 1\n",
        "if step > MAX_EP_STEPS:\n",
        "    done = True\n",
        "next_state = state_next\n",
        "\n",
        "self.buffer.put(state, action, (reward+8)/8, next_state, done)\n",
        "bg_noise = noise\n",
        "episode_reward += reward\n",
        "state = next_state"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWOGHQfSa8JD",
        "outputId": "fdfc23ec-1464-454d-c8f2-183ccdc3fc30"
      },
      "source": [
        "a = np.array([[1, 2], [3, 4]])\n",
        "b = np.array([[5, 6]])\n",
        "c = np.concatenate((a, b), axis=0)\n",
        "print(c)\n",
        "print(np.shape(c))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 2]\n",
            " [3 4]\n",
            " [5 6]]\n",
            "(3, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNoa_iPha9vk"
      },
      "source": [
        "I = 4\n",
        "d_rate = -np.ones((1,I)) * 1\n",
        "hnx1 = np.random.randn(I, I)\n",
        "hnx2 = np.random.randn(I, I)\n",
        "fading_n = hnx1 ** 2 + hnx2 ** 2        \n",
        "state_next = np.concatenate((H * fading_n, d_rate), axis=0)\n",
        "state = np.reshape(state_next,(1,I*I+I))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewD8evpIa_OD"
      },
      "source": [
        "print(state_next)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdlfP4orbAUc"
      },
      "source": [
        "print(state_next[0])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}